{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, n):\n",
    "        data = self.dataset[n]\n",
    "        return self.transform(data[0]), data[1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r'C:\\Users\\chtti\\Downloads\\拍照簽收圖檔-20211027T020311Z-001\\拍照簽收圖檔'\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.AutoAugment(T.autoaugment.AutoAugmentPolicy.IMAGENET),\n",
    "    T.Resize((540, 540)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((540, 540)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(folder)\n",
    "\n",
    "train_length = int(len(dataset) * 0.8)\n",
    "val_length = len(dataset) - train_length\n",
    "train_set, val_set = random_split(dataset, [train_length, val_length], torch.Generator().manual_seed(42))\n",
    "train_set_aug = TransformDataset(train_set, train_transform)\n",
    "val_set_trans = TransformDataset(val_set, val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_set_aug, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          pin_memory=True)\n",
    "val_loader = DataLoader(val_set_trans, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1006"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad', 'good']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=1080x1920 at 0x146AAAFA4F0>, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "plt.rcParams['figure.figsize'] = [24, 8]\n",
    "\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = next(iter(train_loader))\n",
    "# grid = make_grid(sample[0])\n",
    "# show(grid)\n",
    "# print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = next(iter(val_loader))\n",
    "# print(sample[0].shape)\n",
    "# grid = make_grid(sample[0])\n",
    "# show(grid)\n",
    "# print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.resnet18(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['fc.weight', 'fc.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = resnet.state_dict()\n",
    "del d['fc.weight']\n",
    "del d['fc.bias']\n",
    "\n",
    "net.load_state_dict(d, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = net.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(net.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Loss: 0.494035, TestLoss: 0.666929, Acc: 0.549505\n",
      "Batch: 1, Loss: 0.767981, TestLoss: 0.677573, Acc: 0.529703\n",
      "Batch: 2, Loss: 0.588207, TestLoss: 0.677411, Acc: 0.529703\n",
      "Batch: 3, Loss: 0.578859, TestLoss: 0.680105, Acc: 0.529703\n",
      "Batch: 4, Loss: 0.614245, TestLoss: 0.670171, Acc: 0.539604\n",
      "Batch: 5, Loss: 0.688068, TestLoss: 0.675669, Acc: 0.529703\n",
      "Batch: 6, Loss: 0.781302, TestLoss: 0.669249, Acc: 0.539604\n",
      "Batch: 7, Loss: 0.504068, TestLoss: 0.665330, Acc: 0.579208\n",
      "Batch: 8, Loss: 0.754653, TestLoss: 0.665687, Acc: 0.549505\n",
      "Batch: 9, Loss: 0.810816, TestLoss: 0.664055, Acc: 0.544554\n",
      "Batch: 10, Loss: 0.776719, TestLoss: 0.657838, Acc: 0.584158\n",
      "Batch: 11, Loss: 0.842552, TestLoss: 0.661281, Acc: 0.554455\n",
      "Batch: 12, Loss: 0.712167, TestLoss: 0.658559, Acc: 0.589109\n",
      "Batch: 13, Loss: 0.616448, TestLoss: 0.655595, Acc: 0.599010\n",
      "Batch: 14, Loss: 0.774644, TestLoss: 0.656756, Acc: 0.599010\n",
      "Batch: 15, Loss: 0.814387, TestLoss: 0.653264, Acc: 0.618812\n",
      "Batch: 16, Loss: 0.630168, TestLoss: 0.653312, Acc: 0.594059\n",
      "Batch: 17, Loss: 0.781266, TestLoss: 0.650200, Acc: 0.594059\n",
      "Batch: 18, Loss: 0.758002, TestLoss: 0.644687, Acc: 0.623762\n",
      "Batch: 19, Loss: 0.790890, TestLoss: 0.645482, Acc: 0.638614\n",
      "Batch: 20, Loss: 0.648129, TestLoss: 0.635817, Acc: 0.663366\n",
      "Batch: 21, Loss: 0.647224, TestLoss: 0.646039, Acc: 0.623762\n",
      "Batch: 22, Loss: 0.597910, TestLoss: 0.638763, Acc: 0.653465\n",
      "Batch: 23, Loss: 0.601867, TestLoss: 0.640322, Acc: 0.643564\n",
      "Batch: 24, Loss: 0.657707, TestLoss: 0.632893, Acc: 0.648515\n",
      "Batch: 25, Loss: 0.801170, TestLoss: 0.633713, Acc: 0.658416\n",
      "Batch: 26, Loss: 0.642011, TestLoss: 0.635740, Acc: 0.653465\n",
      "Batch: 27, Loss: 0.677515, TestLoss: 0.636120, Acc: 0.648515\n",
      "Batch: 28, Loss: 0.533364, TestLoss: 0.634657, Acc: 0.663366\n",
      "Batch: 29, Loss: 0.623880, TestLoss: 0.633320, Acc: 0.638614\n",
      "Batch: 30, Loss: 0.762217, TestLoss: 0.632178, Acc: 0.673267\n",
      "Batch: 31, Loss: 0.647446, TestLoss: 0.632230, Acc: 0.668317\n",
      "Batch: 32, Loss: 0.572542, TestLoss: 0.628153, Acc: 0.678218\n",
      "Batch: 33, Loss: 0.568309, TestLoss: 0.623806, Acc: 0.673267\n",
      "Batch: 34, Loss: 0.554963, TestLoss: 0.623167, Acc: 0.683168\n",
      "Batch: 35, Loss: 0.757613, TestLoss: 0.621799, Acc: 0.683168\n",
      "Batch: 36, Loss: 0.648677, TestLoss: 0.621877, Acc: 0.688119\n",
      "Batch: 37, Loss: 0.732168, TestLoss: 0.618481, Acc: 0.698020\n",
      "Batch: 38, Loss: 0.546613, TestLoss: 0.619790, Acc: 0.693069\n",
      "Batch: 39, Loss: 0.622007, TestLoss: 0.620924, Acc: 0.688119\n",
      "Batch: 40, Loss: 0.639640, TestLoss: 0.617109, Acc: 0.707921\n",
      "Batch: 41, Loss: 0.641364, TestLoss: 0.613651, Acc: 0.702970\n",
      "Batch: 42, Loss: 0.606717, TestLoss: 0.608195, Acc: 0.737624\n",
      "Batch: 43, Loss: 0.570595, TestLoss: 0.612229, Acc: 0.712871\n",
      "Batch: 44, Loss: 0.578654, TestLoss: 0.613368, Acc: 0.707921\n",
      "Batch: 45, Loss: 0.652326, TestLoss: 0.611601, Acc: 0.717822\n",
      "Batch: 46, Loss: 0.669730, TestLoss: 0.611849, Acc: 0.717822\n",
      "Batch: 47, Loss: 0.729663, TestLoss: 0.606491, Acc: 0.712871\n",
      "Batch: 48, Loss: 0.557265, TestLoss: 0.604191, Acc: 0.727723\n",
      "Batch: 49, Loss: 0.566337, TestLoss: 0.605088, Acc: 0.722772\n",
      "Batch: 50, Loss: 0.588497, TestLoss: 0.605896, Acc: 0.722772\n",
      "Batch: 51, Loss: 0.736436, TestLoss: 0.608783, Acc: 0.732673\n",
      "Batch: 52, Loss: 0.606284, TestLoss: 0.604767, Acc: 0.702970\n",
      "Batch: 53, Loss: 0.648845, TestLoss: 0.598468, Acc: 0.737624\n",
      "Batch: 54, Loss: 0.537966, TestLoss: 0.604203, Acc: 0.722772\n",
      "Batch: 55, Loss: 0.614587, TestLoss: 0.603287, Acc: 0.737624\n",
      "Batch: 56, Loss: 0.550481, TestLoss: 0.597400, Acc: 0.727723\n",
      "Batch: 57, Loss: 0.611773, TestLoss: 0.593108, Acc: 0.737624\n",
      "Batch: 58, Loss: 0.622205, TestLoss: 0.600563, Acc: 0.707921\n",
      "Batch: 59, Loss: 0.737049, TestLoss: 0.598807, Acc: 0.732673\n",
      "Batch: 60, Loss: 0.574547, TestLoss: 0.595604, Acc: 0.732673\n",
      "Batch: 61, Loss: 0.531902, TestLoss: 0.594597, Acc: 0.747525\n",
      "Batch: 62, Loss: 0.600704, TestLoss: 0.587566, Acc: 0.742574\n",
      "Batch: 63, Loss: 0.656400, TestLoss: 0.587389, Acc: 0.737624\n",
      "Batch: 64, Loss: 0.726717, TestLoss: 0.588418, Acc: 0.747525\n",
      "Batch: 65, Loss: 0.588839, TestLoss: 0.584250, Acc: 0.747525\n",
      "Batch: 66, Loss: 0.552504, TestLoss: 0.589816, Acc: 0.732673\n",
      "Batch: 67, Loss: 0.510160, TestLoss: 0.587460, Acc: 0.737624\n",
      "Batch: 68, Loss: 0.729769, TestLoss: 0.582862, Acc: 0.752475\n",
      "Batch: 69, Loss: 0.740026, TestLoss: 0.580877, Acc: 0.752475\n",
      "Batch: 70, Loss: 0.594301, TestLoss: 0.584485, Acc: 0.747525\n",
      "Batch: 71, Loss: 0.639216, TestLoss: 0.584459, Acc: 0.757426\n",
      "Batch: 72, Loss: 0.686000, TestLoss: 0.581724, Acc: 0.752475\n",
      "Batch: 73, Loss: 0.662146, TestLoss: 0.578671, Acc: 0.767327\n",
      "Batch: 74, Loss: 0.745245, TestLoss: 0.576719, Acc: 0.757426\n",
      "Batch: 75, Loss: 0.502922, TestLoss: 0.582402, Acc: 0.767327\n",
      "Batch: 76, Loss: 0.566332, TestLoss: 0.577036, Acc: 0.762376\n",
      "Batch: 77, Loss: 0.769312, TestLoss: 0.575373, Acc: 0.752475\n",
      "Batch: 78, Loss: 0.694259, TestLoss: 0.577163, Acc: 0.757426\n",
      "Batch: 79, Loss: 0.677321, TestLoss: 0.573126, Acc: 0.772277\n",
      "Batch: 80, Loss: 0.731690, TestLoss: 0.570414, Acc: 0.767327\n",
      "Batch: 81, Loss: 0.626236, TestLoss: 0.574374, Acc: 0.767327\n",
      "Batch: 82, Loss: 0.634644, TestLoss: 0.569809, Acc: 0.772277\n",
      "Batch: 83, Loss: 0.705396, TestLoss: 0.564166, Acc: 0.777228\n",
      "Batch: 84, Loss: 0.664552, TestLoss: 0.572077, Acc: 0.767327\n",
      "Batch: 85, Loss: 0.713577, TestLoss: 0.568076, Acc: 0.772277\n",
      "Batch: 86, Loss: 0.615652, TestLoss: 0.572609, Acc: 0.767327\n",
      "Batch: 87, Loss: 0.613901, TestLoss: 0.567709, Acc: 0.767327\n",
      "Batch: 88, Loss: 0.663765, TestLoss: 0.565965, Acc: 0.782178\n",
      "Batch: 89, Loss: 0.514313, TestLoss: 0.563005, Acc: 0.782178\n",
      "Batch: 90, Loss: 0.475389, TestLoss: 0.562072, Acc: 0.787129\n",
      "Batch: 91, Loss: 0.717249, TestLoss: 0.563069, Acc: 0.777228\n",
      "Batch: 92, Loss: 0.666793, TestLoss: 0.556707, Acc: 0.787129\n",
      "Batch: 93, Loss: 0.705701, TestLoss: 0.560007, Acc: 0.787129\n",
      "Batch: 94, Loss: 0.513830, TestLoss: 0.561827, Acc: 0.782178\n",
      "Batch: 95, Loss: 0.696300, TestLoss: 0.558050, Acc: 0.792079\n",
      "Batch: 96, Loss: 0.435881, TestLoss: 0.555703, Acc: 0.792079\n",
      "Batch: 97, Loss: 0.540453, TestLoss: 0.556397, Acc: 0.792079\n",
      "Batch: 98, Loss: 0.669069, TestLoss: 0.552237, Acc: 0.787129\n",
      "Batch: 99, Loss: 0.507368, TestLoss: 0.551634, Acc: 0.792079\n",
      "Batch: 100, Loss: 0.582033, TestLoss: 0.555289, Acc: 0.777228\n",
      "Batch: 101, Loss: 0.498923, TestLoss: 0.554795, Acc: 0.772277\n",
      "Batch: 102, Loss: 0.659321, TestLoss: 0.554123, Acc: 0.806931\n",
      "Batch: 103, Loss: 0.668927, TestLoss: 0.546468, Acc: 0.797030\n",
      "Batch: 104, Loss: 0.580535, TestLoss: 0.547657, Acc: 0.801980\n",
      "Batch: 105, Loss: 0.630452, TestLoss: 0.546857, Acc: 0.797030\n",
      "Batch: 106, Loss: 0.461353, TestLoss: 0.552983, Acc: 0.787129\n",
      "Batch: 107, Loss: 0.382839, TestLoss: 0.546379, Acc: 0.797030\n",
      "Batch: 108, Loss: 0.688063, TestLoss: 0.544886, Acc: 0.782178\n",
      "Batch: 109, Loss: 0.719413, TestLoss: 0.544643, Acc: 0.792079\n",
      "Batch: 110, Loss: 0.557918, TestLoss: 0.540233, Acc: 0.811881\n",
      "Batch: 111, Loss: 0.755757, TestLoss: 0.544494, Acc: 0.806931\n",
      "Batch: 112, Loss: 0.689428, TestLoss: 0.539161, Acc: 0.806931\n",
      "Batch: 113, Loss: 0.674485, TestLoss: 0.542228, Acc: 0.806931\n",
      "Batch: 114, Loss: 0.501542, TestLoss: 0.540464, Acc: 0.821782\n",
      "Batch: 115, Loss: 0.756535, TestLoss: 0.537668, Acc: 0.792079\n",
      "Batch: 116, Loss: 0.648905, TestLoss: 0.540360, Acc: 0.801980\n",
      "Batch: 117, Loss: 0.448107, TestLoss: 0.537748, Acc: 0.821782\n",
      "Batch: 118, Loss: 0.413204, TestLoss: 0.535683, Acc: 0.816832\n",
      "Batch: 119, Loss: 0.681404, TestLoss: 0.537897, Acc: 0.801980\n",
      "Batch: 120, Loss: 0.495467, TestLoss: 0.534779, Acc: 0.797030\n",
      "Batch: 121, Loss: 0.518419, TestLoss: 0.535121, Acc: 0.816832\n",
      "Batch: 122, Loss: 0.679367, TestLoss: 0.532336, Acc: 0.816832\n",
      "Batch: 123, Loss: 0.487391, TestLoss: 0.529811, Acc: 0.811881\n",
      "Batch: 124, Loss: 0.684441, TestLoss: 0.531743, Acc: 0.811881\n",
      "Batch: 125, Loss: 0.517035, TestLoss: 0.532280, Acc: 0.821782\n",
      "Batch: 126, Loss: 0.734027, TestLoss: 0.530207, Acc: 0.826733\n",
      "Batch: 127, Loss: 0.458739, TestLoss: 0.525958, Acc: 0.811881\n",
      "Batch: 128, Loss: 0.506338, TestLoss: 0.526297, Acc: 0.816832\n",
      "Batch: 129, Loss: 0.691357, TestLoss: 0.527019, Acc: 0.826733\n",
      "Batch: 130, Loss: 0.737921, TestLoss: 0.527796, Acc: 0.826733\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ed99840ec31b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_EPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-57b0f9face92>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \"\"\"\n\u001b[0;32m    231\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MAX_EPOCH = 20000\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    net.train()\n",
    "    for i, (data, label) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        pred = net(data)\n",
    "        loss = loss_fn(pred, label)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, correct = 0, 0\n",
    "            for i, (data, label) in enumerate(val_loader):\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "                \n",
    "                pred = net(data)\n",
    "                val_loss += loss_fn(pred, label).item()\n",
    "                correct += (pred.argmax(1) == label).type(torch.float).sum().item()\n",
    "                \n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        correct /= len(val_loader.dataset)\n",
    "        print('Batch: {}, Loss: {:>5f}, TestLoss: {:>5f}, Acc: {:>2f}'.format(\n",
    "            epoch, loss.item(), val_loss, correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'model_211201.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_name = ['bad', 'good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17934/1919895076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcls_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "cls_name = dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('model_211201.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_pyfunc\n",
    "\n",
    "from importlib import reload\n",
    "image_pyfunc = reload(image_pyfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/12/05 22:32:26 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.11.0a0+d3722d3) contains a local version label (+d3722d3). MLflow logged a pip requirement for this package as 'torchvision==0.11.0a0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'mlflow-env',\n",
       " 'channels': ['conda-forge'],\n",
       " 'dependencies': ['python=3.9.7',\n",
       "  'pip',\n",
       "  {'pip': ['mlflow',\n",
       "    'torch==1.10.0',\n",
       "    'torchvision==0.11.0a0',\n",
       "    'cloudpickle==2.0.0']}]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.pytorch.get_default_conda_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad', 'good']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/12/05 22:32:27 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.11.0a0+d3722d3) contains a local version label (+d3722d3). MLflow logged a pip requirement for this package as 'torchvision==0.11.0a0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2021/12/05 22:32:28 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.11.0a0+d3722d3) contains a local version label (+d3722d3). MLflow logged a pip requirement for this package as 'torchvision==0.11.0a0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    }
   ],
   "source": [
    "image_pyfunc.save_pytorch_model(net, 'model', (1, 3, 540, 540), cls_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_pytorch_env_patch():\n",
    "#     e = mlflow.pytorch.get_default_conda_env()\n",
    "#     e['channels'].append('pytorch')\n",
    "#     e['dependencies'].extend(['pytorch', 'torchvision', 'torchaudio', 'cudatoolkit=11.3'])\n",
    "#     find_pip = tuple(filter(lambda p: isinstance(p, dict) and 'pip' in p, e['dependencies']))\n",
    "#     find_torch = tuple(filter(lambda p: 'torch' in p, find_pip[0]['pip']))\n",
    "#     for p in find_torch:\n",
    "#         find_pip[0]['pip'].remove(p)\n",
    "#     return e    \n",
    "#     \n",
    "# print(get_pytorch_env_patch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
